<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.20"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>TECA: teca_pytorch_algorithm.teca_pytorch_algorithm Class Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
</script>
<script type="text/javascript" async="async" src="https://cdn.jsdelivr.net/npm/mathjax@2/MathJax.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 56px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">TECA
   </div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.20 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div id="nav-path" class="navpath">
  <ul>
<li class="navelem"><b>teca_pytorch_algorithm</b></li><li class="navelem"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html">teca_pytorch_algorithm</a></li>  </ul>
</div>
</div><!-- top -->
<div class="header">
  <div class="summary">
<a href="#pub-methods">Public Member Functions</a> &#124;
<a href="#pub-attribs">Public Attributes</a> &#124;
<a href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm-members.html">List of all members</a>  </div>
  <div class="headertitle">
<div class="title">teca_pytorch_algorithm.teca_pytorch_algorithm Class Reference</div>  </div>
</div><!--header-->
<div class="contents">
<div class="dynheader">
Inheritance diagram for teca_pytorch_algorithm.teca_pytorch_algorithm:</div>
<div class="dyncontent">
 <div class="center">
  <img src="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.png" alt=""/>
 </div></div>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-methods"></a>
Public Member Functions</h2></td></tr>
<tr class="memitem:a320360274ff5e3982ca1cc7c3b17e3e6"><td class="memItemLeft" align="right" valign="top"><a id="a320360274ff5e3982ca1cc7c3b17e3e6"></a>
def&#160;</td><td class="memItemRight" valign="bottom"><b>__init__</b> (self)</td></tr>
<tr class="separator:a320360274ff5e3982ca1cc7c3b17e3e6"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a229eaaf36eddd9fa23d8b81c28dc041a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a229eaaf36eddd9fa23d8b81c28dc041a">set_verbose</a> (self, val)</td></tr>
<tr class="separator:a229eaaf36eddd9fa23d8b81c28dc041a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ad1507779b7d01c0c10088da5a5f0870d"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#ad1507779b7d01c0c10088da5a5f0870d">set_input_variable</a> (self, name)</td></tr>
<tr class="separator:ad1507779b7d01c0c10088da5a5f0870d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a1fa822bcb29de005ec14378288729997"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a1fa822bcb29de005ec14378288729997">set_output_variable</a> (self, name, atts)</td></tr>
<tr class="separator:a1fa822bcb29de005ec14378288729997"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a5bc74b4798a867e7abb3eb2211768309"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a5bc74b4798a867e7abb3eb2211768309">set_thread_pool_size</a> (self, val)</td></tr>
<tr class="separator:a5bc74b4798a867e7abb3eb2211768309"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af557c1b79fe84f0eacf3d1d295ca22c2"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#af557c1b79fe84f0eacf3d1d295ca22c2">set_max_thread_pool_size</a> (self, val)</td></tr>
<tr class="separator:af557c1b79fe84f0eacf3d1d295ca22c2"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a01d116ee8e08f49e7045bdf56a9bde6a"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a01d116ee8e08f49e7045bdf56a9bde6a">set_target_device</a> (self, val)</td></tr>
<tr class="separator:a01d116ee8e08f49e7045bdf56a9bde6a"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a9ef9386d0963f1f816ca03d6cf889026"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a9ef9386d0963f1f816ca03d6cf889026">set_model</a> (self, model)</td></tr>
<tr class="separator:a9ef9386d0963f1f816ca03d6cf889026"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:acee6ec756857714d1f099250787ad293"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#acee6ec756857714d1f099250787ad293">initialize</a> (self)</td></tr>
<tr class="separator:acee6ec756857714d1f099250787ad293"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a12d164756aadc89671063746a0db5dbe"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a12d164756aadc89671063746a0db5dbe">check_initialized</a> (self)</td></tr>
<tr class="separator:a12d164756aadc89671063746a0db5dbe"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afafb85cdb8fd9591edc0af9baa127695"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#afafb85cdb8fd9591edc0af9baa127695">load_state_dict</a> (self, filename)</td></tr>
<tr class="separator:afafb85cdb8fd9591edc0af9baa127695"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8228896d9208060d3e84e30da80644ff"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a8228896d9208060d3e84e30da80644ff">load_model</a> (self, filename, model)</td></tr>
<tr class="separator:a8228896d9208060d3e84e30da80644ff"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a7c868e11a1729d4b11c5273f60b177c0"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a7c868e11a1729d4b11c5273f60b177c0">preprocess</a> (self, in_array)</td></tr>
<tr class="separator:a7c868e11a1729d4b11c5273f60b177c0"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a8a33644ef781c322070171e080dd2591"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#a8a33644ef781c322070171e080dd2591">postprocess</a> (self, out_tensor)</td></tr>
<tr class="separator:a8a33644ef781c322070171e080dd2591"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:af102ddbe4bbb14fa758e019c69ec1258"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#af102ddbe4bbb14fa758e019c69ec1258">report</a> (self, port, rep_in)</td></tr>
<tr class="separator:af102ddbe4bbb14fa758e019c69ec1258"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aa21f59a5d3e00b94b2f1a3779f26599e"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#aa21f59a5d3e00b94b2f1a3779f26599e">request</a> (self, port, md_in, req_in)</td></tr>
<tr class="separator:aa21f59a5d3e00b94b2f1a3779f26599e"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:afe15e4afdb70568feb5aeefa8c81f340"><td class="memItemLeft" align="right" valign="top">def&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classteca__pytorch__algorithm_1_1teca__pytorch__algorithm.html#afe15e4afdb70568feb5aeefa8c81f340">execute</a> (self, port, data_in, req)</td></tr>
<tr class="separator:afe15e4afdb70568feb5aeefa8c81f340"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 class="groupheader"><a name="pub-attribs"></a>
Public Attributes</h2></td></tr>
<tr class="memitem:a2a0ff746841011b1b16e406f41397a4d"><td class="memItemLeft" align="right" valign="top"><a id="a2a0ff746841011b1b16e406f41397a4d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>input_variable</b></td></tr>
<tr class="separator:a2a0ff746841011b1b16e406f41397a4d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a99c6c98120af7bdaa18d705479ba14da"><td class="memItemLeft" align="right" valign="top"><a id="a99c6c98120af7bdaa18d705479ba14da"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>output_variable</b></td></tr>
<tr class="separator:a99c6c98120af7bdaa18d705479ba14da"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:aefb9a68c5f53289e23861f46bc79529b"><td class="memItemLeft" align="right" valign="top"><a id="aefb9a68c5f53289e23861f46bc79529b"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>output_variable_atts</b></td></tr>
<tr class="separator:aefb9a68c5f53289e23861f46bc79529b"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a168e3aa6099ee6cc17c400d226b4198d"><td class="memItemLeft" align="right" valign="top"><a id="a168e3aa6099ee6cc17c400d226b4198d"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>model</b></td></tr>
<tr class="separator:a168e3aa6099ee6cc17c400d226b4198d"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a43610972df948796be3e114983b703ce"><td class="memItemLeft" align="right" valign="top"><a id="a43610972df948796be3e114983b703ce"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>model_path</b></td></tr>
<tr class="separator:a43610972df948796be3e114983b703ce"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a830a34ef3e9b6aea0a73a4c82a4a0f3f"><td class="memItemLeft" align="right" valign="top"><a id="a830a34ef3e9b6aea0a73a4c82a4a0f3f"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>device</b></td></tr>
<tr class="separator:a830a34ef3e9b6aea0a73a4c82a4a0f3f"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a50017e35e87c9095feb927b1c3f18502"><td class="memItemLeft" align="right" valign="top"><a id="a50017e35e87c9095feb927b1c3f18502"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>n_threads</b></td></tr>
<tr class="separator:a50017e35e87c9095feb927b1c3f18502"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a0ad0f56d17db0699163d6c892716a8dd"><td class="memItemLeft" align="right" valign="top"><a id="a0ad0f56d17db0699163d6c892716a8dd"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>n_threads_max</b></td></tr>
<tr class="separator:a0ad0f56d17db0699163d6c892716a8dd"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:ac2ede51e5f3d0addfda090c96729f751"><td class="memItemLeft" align="right" valign="top"><a id="ac2ede51e5f3d0addfda090c96729f751"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>verbose</b></td></tr>
<tr class="separator:ac2ede51e5f3d0addfda090c96729f751"><td class="memSeparator" colspan="2">&#160;</td></tr>
<tr class="memitem:a6d6605712a6c5047de1fbab50eae8ec0"><td class="memItemLeft" align="right" valign="top"><a id="a6d6605712a6c5047de1fbab50eae8ec0"></a>
&#160;</td><td class="memItemRight" valign="bottom"><b>initialized</b></td></tr>
<tr class="separator:a6d6605712a6c5047de1fbab50eae8ec0"><td class="memSeparator" colspan="2">&#160;</td></tr>
</table>
<a name="details" id="details"></a><h2 class="groupheader">Detailed Description</h2>
<div class="textblock"><pre class="fragment">A TECA algorithm that provides access to torch. To use this class, derive
a new class from it and from your class:

1. call set input_/output_variable. this tells the pytorch_algorithm
   which array to process and how to name the result.

2. call set_model. this installs your torch model. Use load_state_dict
   to load state dict from the file system in parallel.

3. override preprocess. The input numpy array is passed in.  return the
   array to send to torch after applying any preprocessing or transforms.

4. override postprocess. the tensor returned from torch is passed. return a
   numpy array with the correct mesh dimensions

5. Optionally override the usual teca_python_algorithm methods as needed.</pre> </div><h2 class="groupheader">Member Function Documentation</h2>
<a id="a12d164756aadc89671063746a0db5dbe"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a12d164756aadc89671063746a0db5dbe">&#9670;&nbsp;</a></span>check_initialized()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.check_initialized </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">verify that the user called initialize
</pre> 
</div>
</div>
<a id="afe15e4afdb70568feb5aeefa8c81f340"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afe15e4afdb70568feb5aeefa8c81f340">&#9670;&nbsp;</a></span>execute()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.execute </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>port</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>data_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>req</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> TECA execute override </pre> 
</div>
</div>
<a id="acee6ec756857714d1f099250787ad293"></a>
<h2 class="memtitle"><span class="permalink"><a href="#acee6ec756857714d1f099250787ad293">&#9670;&nbsp;</a></span>initialize()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.initialize </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">determine the mapping to hardware for the current MPI layout.
if device is cpu then this configures OpenMP such that its
thread pools have 1 thread per physical core.
this also imports torch. this must be called prior to using any
torch api's etc.
</pre> 
</div>
</div>
<a id="a8228896d9208060d3e84e30da80644ff"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8228896d9208060d3e84e30da80644ff">&#9670;&nbsp;</a></span>load_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.load_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>filename</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Load the state dict named by 'filename' and install them into the
passed model instance 'model'. This also moves the model on the current
target device, and puts the model into inference mode.
</pre> 
</div>
</div>
<a id="afafb85cdb8fd9591edc0af9baa127695"></a>
<h2 class="memtitle"><span class="permalink"><a href="#afafb85cdb8fd9591edc0af9baa127695">&#9670;&nbsp;</a></span>load_state_dict()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.load_state_dict </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>filename</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Load only the pytorch state_dict parameters file.
</pre> 
</div>
</div>
<a id="a8a33644ef781c322070171e080dd2591"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a33644ef781c322070171e080dd2591">&#9670;&nbsp;</a></span>postprocess()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.postprocess </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>out_tensor</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Override this to postprocess the tensor data returned from torch.
return the result as a numpy array. the return should be sized
compatibly with the output mesh. The default implementation converts
the tensor to a ndarray.
</pre> 
</div>
</div>
<a id="a7c868e11a1729d4b11c5273f60b177c0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7c868e11a1729d4b11c5273f60b177c0">&#9670;&nbsp;</a></span>preprocess()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.preprocess </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>in_array</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Override this to preprocess the passed in array before it is passed to
torch. The passed array has the shape of the input/output mesh. the
default implementation does nothing.
</pre> 
</div>
</div>
<a id="af102ddbe4bbb14fa758e019c69ec1258"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af102ddbe4bbb14fa758e019c69ec1258">&#9670;&nbsp;</a></span>report()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.report </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>port</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>rep_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> TECA report override </pre> 
</div>
</div>
<a id="aa21f59a5d3e00b94b2f1a3779f26599e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa21f59a5d3e00b94b2f1a3779f26599e">&#9670;&nbsp;</a></span>request()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.request </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>port</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>md_in</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>req_in</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment"> TECA request override </pre> 
</div>
</div>
<a id="ad1507779b7d01c0c10088da5a5f0870d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad1507779b7d01c0c10088da5a5f0870d">&#9670;&nbsp;</a></span>set_input_variable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_input_variable </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">set the name of the variable to be processed
</pre> 
</div>
</div>
<a id="af557c1b79fe84f0eacf3d1d295ca22c2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#af557c1b79fe84f0eacf3d1d295ca22c2">&#9670;&nbsp;</a></span>set_max_thread_pool_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_max_thread_pool_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Set aniupper bound on the thread pool size. This is applied
during automatic thread pool sizing.
</pre> 
</div>
</div>
<a id="a9ef9386d0963f1f816ca03d6cf889026"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9ef9386d0963f1f816ca03d6cf889026">&#9670;&nbsp;</a></span>set_model()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_model </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>model</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">set PyTorch model
</pre> 
</div>
</div>
<a id="a1fa822bcb29de005ec14378288729997"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1fa822bcb29de005ec14378288729997">&#9670;&nbsp;</a></span>set_output_variable()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_output_variable </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>name</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>atts</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">set the variable name to store the results under and
its attributes. Attributes are optional and may be None
but are required for the CF writer to write the result
to disk.
</pre> 
</div>
</div>
<a id="a01d116ee8e08f49e7045bdf56a9bde6a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a01d116ee8e08f49e7045bdf56a9bde6a">&#9670;&nbsp;</a></span>set_target_device()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_target_device </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Set the target device. May be one of 'cpu' or 'cuda'.
</pre> 
</div>
</div>
<a id="a5bc74b4798a867e7abb3eb2211768309"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5bc74b4798a867e7abb3eb2211768309">&#9670;&nbsp;</a></span>set_thread_pool_size()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_thread_pool_size </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Set the number of threads in each rank's thread pool. Setting
to a value of -1 will result in the thread pool being sized
such that each thread is uniquely and exclusively bound to a
specific core accounting for thread pools in other ranks
running on the same node
</pre> 
</div>
</div>
<a id="a229eaaf36eddd9fa23d8b81c28dc041a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a229eaaf36eddd9fa23d8b81c28dc041a">&#9670;&nbsp;</a></span>set_verbose()</h2>

<div class="memitem">
<div class="memproto">
      <table class="memname">
        <tr>
          <td class="memname">def teca_pytorch_algorithm.teca_pytorch_algorithm.set_verbose </td>
          <td>(</td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>self</em>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">&#160;</td>
          <td class="paramname"><em>val</em>&#160;</td>
        </tr>
        <tr>
          <td></td>
          <td>)</td>
          <td></td><td></td>
        </tr>
      </table>
</div><div class="memdoc">
<pre class="fragment">Set the verbosity of the run, higher values will result in more
terminal output
</pre> 
</div>
</div>
<hr/>The documentation for this class was generated from the following file:<ul>
<li>TECA/alg/teca_pytorch_algorithm.py</li>
</ul>
</div><!-- contents -->
<!-- start footer part -->
<hr class="footer"/><address class="footer"><small>
Generated by&#160;<a href="http://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.8.20
</small></address>
</body>
</html>
